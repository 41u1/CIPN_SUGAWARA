import numpy as np
import cv2
import cv2.aruco as aruco
import glob
import os
from pathlib import Path

# ==========================================================
# === è¨­å®šã‚¨ãƒªã‚¢ ===========================================
# ==========================================================
# 1. å…¥åŠ›: å‹•ç”»ãŒã‚ã‚‹ãƒ•ã‚©ãƒ«ãƒ€
TARGET_DIR = r"C:\Users\yuich\python_project\project_analysis_main_research\data\1_processed\calib_trimed\CIPN\P003\Setting1"

# 2. å‡ºåŠ›: çµæœ(.npz)ã‚’ä¿å­˜ã™ã‚‹ãƒ•ã‚©ãƒ«ãƒ€
OUTPUT_DIR = TARGET_DIR

# 3. ChArUcoãƒœãƒ¼ãƒ‰ã®è¨­å®š
SQUARES_VERTICALLY = 4     # è¡Œæ•°
SQUARES_HORIZONTALLY = 6   # åˆ—æ•°
SQUARE_LENGTH = 0.087      # ãƒã‚¹ã®ã‚µã‚¤ã‚º (m)
MARKER_LENGTH = 0.065      # ãƒãƒ¼ã‚«ãƒ¼ã®ã‚µã‚¤ã‚º (m)
DICTIONARY_VAR = aruco.DICT_4X4_50 # ä½¿ç”¨ã—ãŸè¾æ›¸

# 4. è§£æé–“éš” (å¤‰æ›´ç‚¹: 45 -> 15 ã¸ç´°ã‹ãã—ã¦ãƒ‡ãƒ¼ã‚¿æ•°ã‚’ç¨¼ã)
FRAME_STEP = 45

# ==========================================================
# === é–¢æ•°å®šç¾©: ãƒœãƒ¼ãƒ‰ç”Ÿæˆ =================================
# ==========================================================
def get_charuco_board():
    dictionary = aruco.getPredefinedDictionary(DICTIONARY_VAR)
    board = aruco.CharucoBoard(
        (SQUARES_HORIZONTALLY, SQUARES_VERTICALLY),
        SQUARE_LENGTH,
        MARKER_LENGTH,
        dictionary
    )
    try: board.setLegacyPattern(True)
    except: pass
    return board, dictionary

# ==========================================================
# === é–¢æ•°å®šç¾©: å˜çœ¼ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ =====================
# ==========================================================
def run_mono_calibration(video_path, camera_name, save_path):
    print(f"\nğŸš€ [{camera_name}] å˜çœ¼è§£æã‚’é–‹å§‹: {Path(video_path).name}")
    
    board, dictionary = get_charuco_board()
    cap = cv2.VideoCapture(video_path)
    
    objpoints = [] # 3Dåº§æ¨™
    imgpoints = [] # 2Dåº§æ¨™
    
    img_size = None
    frame_count = 0
    valid_frames = 0
    
    all_board_corners = board.getChessboardCorners()

    while True:
        ret, frame = cap.read()
        if not ret: break
        
        if frame_count % FRAME_STEP == 0:
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            if img_size is None:
                img_size = gray.shape[::-1]
            
            corners, ids, _ = aruco.detectMarkers(gray, dictionary)
            if len(corners) > 0:
                _, c_corners, c_ids = aruco.interpolateCornersCharuco(corners, ids, gray, board)
                
                # ç‚¹ãŒ6å€‹ä»¥ä¸Šã‚ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ã ã‘æ¡ç”¨
                if c_corners is not None and len(c_corners) > 5:
                    current_obj_pts = []
                    for c_id in c_ids:
                        current_obj_pts.append(all_board_corners[c_id[0]])
                    
                    objpoints.append(np.array(current_obj_pts, dtype=np.float32))
                    imgpoints.append(c_corners)
                    
                    valid_frames += 1
                    print(f"  [{camera_name}] Frame {frame_count}: OK (Total {valid_frames})", end="\r")
        frame_count += 1
    
    cap.release()
    print(f"\n  âœ… ãƒ‡ãƒ¼ã‚¿åé›†å®Œäº†: {valid_frames} æš")

    if valid_frames < 10:
        print(f"  âŒ ã‚¨ãƒ©ãƒ¼: [{camera_name}] æœ‰åŠ¹ãªãƒ•ãƒ¬ãƒ¼ãƒ ãŒè¶³ã‚Šã¾ã›ã‚“ã€‚")
        return None, None

    print(f"  ğŸ§® è¨ˆç®—ä¸­ (æ¨™æº–ãƒ¢ãƒ¼ãƒ‰)...")
    try:
        ret, mtx, dist, _, _ = cv2.calibrateCamera(
            objpoints, imgpoints, img_size, None, None
        )
        print(f"  âœ¨ {camera_name} å®Œäº†! èª¤å·®: {ret:.4f} px")
        
        np.savez(save_path, mtx=mtx, dist=dist, ret=ret)
        print(f"  ğŸ’¾ ä¿å­˜: {save_path}")
        return mtx, dist
    except Exception as e:
        print(f"  âŒ è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
        return None, None

# ==========================================================
# === é–¢æ•°å®šç¾©: ã‚¹ãƒ†ãƒ¬ã‚ªã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ (æ”¹è‰¯ç‰ˆ) ========
# ==========================================================
def run_stereo_calibration_process(video_c1, video_c2, mtx1, dist1, mtx2, dist2, save_path):
    print(f"\nğŸš€ [Stereo] ã‚¹ãƒ†ãƒ¬ã‚ªè§£æã‚’é–‹å§‹...")
    
    board, dictionary = get_charuco_board()
    cap1 = cv2.VideoCapture(video_c1)
    cap2 = cv2.VideoCapture(video_c2)
    
    objpoints = []
    imgpoints_l = []
    imgpoints_r = []
    
    frame_count = 0
    valid_pairs = 0
    img_size = None
    all_board_corners = board.getChessboardCorners()

    while True:
        ret1, frame1 = cap1.read()
        ret2, frame2 = cap2.read()
        if not ret1 or not ret2: break
        
        if frame_count % FRAME_STEP == 0:
            gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)
            gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)
            if img_size is None: img_size = gray1.shape[::-1]

            corners1, ids1, _ = aruco.detectMarkers(gray1, dictionary)
            corners2, ids2, _ = aruco.detectMarkers(gray2, dictionary)

            if len(corners1) > 0 and len(corners2) > 0:
                _, c_corners1, c_ids1 = aruco.interpolateCornersCharuco(corners1, ids1, gray1, board)
                _, c_corners2, c_ids2 = aruco.interpolateCornersCharuco(corners2, ids2, gray2, board)

                if c_corners1 is not None and c_corners2 is not None:
                    if len(c_corners1) > 5 and len(c_corners2) > 5:
                        common_ids = np.intersect1d(c_ids1, c_ids2)
                        
                        # å…±é€šã—ã¦å†™ã£ã¦ã„ã‚‹ç‚¹ãŒ6å€‹ä»¥ä¸Šãªã‚‰æ¡ç”¨
                        if len(common_ids) > 6:
                            obj_pts_tmp = []
                            img_pts_l_tmp = []
                            img_pts_r_tmp = []

                            for cid in common_ids:
                                idx1 = np.where(c_ids1 == cid)[0][0]
                                idx2 = np.where(c_ids2 == cid)[0][0]
                                img_pts_l_tmp.append(c_corners1[idx1])
                                img_pts_r_tmp.append(c_corners2[idx2])
                                obj_pts_tmp.append(all_board_corners[cid])

                            imgpoints_l.append(np.array(img_pts_l_tmp, dtype=np.float32))
                            imgpoints_r.append(np.array(img_pts_r_tmp, dtype=np.float32))
                            objpoints.append(np.array(obj_pts_tmp, dtype=np.float32))
                            
                            valid_pairs += 1
                            print(f"  [Stereo] Frame {frame_count}: Pair Found (Total {valid_pairs})", end="\r")
        frame_count += 1
    
    cap1.release()
    cap2.release()
    print(f"\n  âœ… ãƒ‡ãƒ¼ã‚¿åé›†å®Œäº†: {valid_pairs} çµ„")

    if valid_pairs < 10:
        print("  âŒ ã‚¨ãƒ©ãƒ¼: ãƒšã‚¢ãŒè¶³ã‚Šã¾ã›ã‚“ã€‚")
        return

    print("  ğŸ§® ç›¸å¯¾ä½ç½®(R, T)ã‚’è¨ˆç®—ä¸­ (USE_INTRINSIC_GUESS)...")
    
    # ã€é‡è¦å¤‰æ›´ç‚¹ã€‘å¾®èª¿æ•´ã‚’è¨±å¯ã™ã‚‹ãƒ•ãƒ©ã‚°ã‚’ä½¿ç”¨
    flags = cv2.CALIB_USE_INTRINSIC_GUESS
    
    # ã€é‡è¦å¤‰æ›´ç‚¹ã€‘æˆ»ã‚Šå€¤ã® new_mtx, new_dist ã‚’å—ã‘å–ã‚‹
    ret, new_mtx1, new_dist1, new_mtx2, new_dist2, R, T, E, F = cv2.stereoCalibrate(
        objpoints, imgpoints_l, imgpoints_r,
        mtx1, dist1, mtx2, dist2,
        img_size, criteria=(cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 1e-5),
        flags=flags
    )
    
    print(f"\nğŸ“Š æœ€çµ‚çµæœãƒ¬ãƒãƒ¼ãƒˆ")
    print(f"  RMS Error: {ret:.4f} pixel")
    print(f"  ä¸¦é€²ãƒ™ã‚¯ãƒˆãƒ« T (è·é›¢ [m]):\n{T}")
    
    # ã€é‡è¦å¤‰æ›´ç‚¹ã€‘æœ€é©åŒ–ã•ã‚ŒãŸæ–°ã—ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä¿å­˜ã™ã‚‹
    np.savez(save_path, 
             mtx1=new_mtx1, dist1=new_dist1, 
             mtx2=new_mtx2, dist2=new_dist2, 
             R=R, T=T, ret=ret)
    print(f"\nğŸ’¾ å…¨å·¥ç¨‹å®Œäº†! ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: {save_path}")

# ==========================================================
# === ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œå‡¦ç† =======================================
# ==========================================================
if __name__ == "__main__":
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)

    search_path = Path(TARGET_DIR)
    
    # MP4ã¨MOVã®ä¸¡æ–¹ã«å¯¾å¿œ
    c1_files = list(search_path.glob("*_C1_*.mp4")) + list(search_path.glob("*_C1_*.MOV"))
    c2_files = list(search_path.glob("*_C2_*.mp4")) + list(search_path.glob("*_C2_*.MOV"))

    if not c1_files or not c2_files:
        print(f"âŒ æŒ‡å®šãƒ•ã‚©ãƒ«ãƒ€ã«å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {TARGET_DIR}")
    else:
        video_c1 = str(c1_files[0])
        video_c2 = str(c2_files[0])
        
        out_path = Path(OUTPUT_DIR)
        path_c1_res = str(out_path / "calibration_result_C1.npz")
        path_c2_res = str(out_path / "calibration_result_C2.npz")
        path_stereo_res = str(out_path / "camera_params_stereo.npz")

        # Step 1: å·¦ã‚«ãƒ¡ãƒ©
        mtx1, dist1 = run_mono_calibration(video_c1, "Camera 1 (Left)", path_c1_res)
        
        # Step 2: å³ã‚«ãƒ¡ãƒ©
        if mtx1 is not None:
            mtx2, dist2 = run_mono_calibration(video_c2, "Camera 2 (Right)", path_c2_res)

            # Step 3: ã‚¹ãƒ†ãƒ¬ã‚ª
            if mtx2 is not None:
                run_stereo_calibration_process(video_c1, video_c2, mtx1, dist1, mtx2, dist2, path_stereo_res)